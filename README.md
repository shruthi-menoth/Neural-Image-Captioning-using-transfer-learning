# Neural-Image-Captioning-using-transfer-learning
Image captioning uses techniques from computer vision and natural language processing to predict the content of the images. To implement this, we train the model integrating both the subfields using various datasets. Datasets usually contains a plethora of images, which is both computationally expensive and time consuming to train. We propose a scheme to employ transfer learning in pre-trained models  to reduce the complexity of the training phase in new datasets. This report also explains about how we used transfer learning to a model which performs a different task, to make it perform our task. Experiments on  various datasets have been conducted and results have been tabulated. We analyze the accuracy of the model both qualitatively and quantitatively.
